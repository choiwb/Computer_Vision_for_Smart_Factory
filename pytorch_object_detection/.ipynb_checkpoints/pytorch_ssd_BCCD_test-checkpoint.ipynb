{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dataset':'BCCD',  # VOC → BCCD\n",
    "        'basenet':'vgg16_reducedfc.pth',\n",
    "        'batch_size':32,\n",
    "        'resume':'',\n",
    "        'start_iter':0,\n",
    "        'num_workers':0,  # 4 → 0\n",
    "        'cuda':True,  # Macの場合False\n",
    "        'lr':5e-4,\n",
    "        'momentum':0.9,\n",
    "        'weight_decay':5e-4,\n",
    "        'gamma':0.1,\n",
    "        'save_folder':'weights/'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if args['cuda']:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    if not args['cuda']:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    " \n",
    "if not os.path.exists(args['save_folder']):\n",
    "    os.mkdir(args['save_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info[0] == 2:\n",
    "    import xml.etree.cElementTree as ET\n",
    "else:\n",
    "    import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_CLASSES = ('scratch', 'fraction')  # 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCAnnotationTransform(object):\n",
    "    def __init__(self, class_to_ind=None, keep_difficult=False):\n",
    "        self.class_to_ind = class_to_ind or dict(\n",
    "            zip(VOC_CLASSES, range(len(VOC_CLASSES))))\n",
    "        self.keep_difficult = keep_difficult\n",
    "\n",
    "    def __call__(self, target, width, height):\n",
    "        res = []\n",
    "        for obj in target.iter('object'):\n",
    "            difficult = int(obj.find('difficult').text) == 1\n",
    "            if not self.keep_difficult and difficult:\n",
    "                continue\n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bbox = obj.find('bndbox')\n",
    "\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            bndbox = []\n",
    "            for i, pt in enumerate(pts):\n",
    "                cur_pt = int(bbox.find(pt).text) - 1\n",
    "                cur_pt = cur_pt / width if i % 2 == 0 else cur_pt / height\n",
    "                bndbox.append(cur_pt)\n",
    "            label_idx = self.class_to_ind[name]\n",
    "            bndbox.append(label_idx)\n",
    "            res += [bndbox]  \n",
    "        return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDetection(data.Dataset):\n",
    "    def __init__(self, root,\n",
    "                 image_sets=[('BCCD', 'trainval')],  # 修正  \n",
    "                 transform=None, target_transform=VOCAnnotationTransform(),\n",
    "                 dataset_name='VOC0712'):\n",
    "        self.root = root\n",
    "        self.image_set = image_sets\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.name = dataset_name\n",
    "        self._annopath = osp.join('%s', 'Annotations', '%s.xml')\n",
    "        self._imgpath = osp.join('%s', 'JPEGImages', '%s.jpg')\n",
    "        self.ids = list()\n",
    "        for (dir, name) in image_sets:  # 修正\n",
    "            rootpath = osp.join(self.root, dir)  # 修正\n",
    "            for line in open(osp.join(rootpath, 'ImageSets', 'Main', name + '.txt')):\n",
    "                self.ids.append((rootpath, line.strip()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im, gt, h, w = self.pull_item(index)\n",
    "\n",
    "        return im, gt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        img_id = self.ids[index]\n",
    "\n",
    "        target = ET.parse(self._annopath % img_id).getroot()\n",
    "        img = cv2.imread(self._imgpath % img_id)\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target, width, height)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            target = np.array(target)\n",
    "            img, boxes, labels = self.transform(img, target[:, :4], target[:, 4])\n",
    "            img = img[:, :, (2, 1, 0)]\n",
    "            target = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "        return torch.from_numpy(img).permute(2, 0, 1), target, height, width\n",
    "\n",
    "    def pull_image(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        return cv2.imread(self._imgpath % img_id, cv2.IMREAD_COLOR)\n",
    "\n",
    "    def pull_anno(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        anno = ET.parse(self._annopath % img_id).getroot()\n",
    "        gt = self.target_transform(anno, 1, 1)\n",
    "        return img_id[1], gt\n",
    "\n",
    "    def pull_tensor(self, index):\n",
    "        return torch.Tensor(self.pull_image(index)).unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD300 CONFIGS\n",
    "voc = {\n",
    "    'num_classes': 21,\n",
    "    # handbook\n",
    "    #'lr_steps': (80000, 100000, 120000),\n",
    "    #'max_iter': 120000,\n",
    "    'lr_steps': (8000, 10000, 12000),\n",
    "    'max_iter': 3000,  # 12000 → 3000\n",
    "    # handbook\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'min_dim': 300,\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': True,\n",
    "    'name': 'BCCD',  # 'VOC' → 'BCCD' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
